<!DOCTYPE html>
<html  >
<head>
  <!-- Site made with Mobirise Website Builder v5.3.5, https://mobirise.com -->
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Mobirise v5.3.5, mobirise.com">
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/logo.png" type="image/x-icon">
  <meta name="description" content="">
  
  
  <title>Facial Expression Recognition</title>
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons2/mobirise2.css">
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons/mobirise-icons.css">
  <link rel="stylesheet" href="assets/tether/tether.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/socicon/css/styles.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Jost:100,200,300,400,500,600,700,800,900,100i,200i,300i,400i,500i,600i,700i,800i,900i&display=swap"></noscript>
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">
  
  
  
  
</head>
<body>
  
  <section class="menu menu1 cid-sA64Nacepq" once="menu" id="menu1-1o">
    

    <nav class="navbar navbar-dropdown navbar-fixed-top navbar-expand-lg">
        <div class="container">
            <div class="navbar-brand">
                
                <span class="navbar-caption-wrap"><a class="navbar-caption text-black text-primary display-7" href="index.html">ALL ABOUT FACE</a></span>
            </div>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarNavAltMarkup" aria-expanded="false" aria-label="Toggle navigation">
                <div class="hamburger">
                    <span></span>
                    <span></span>
                    <span></span>
                    <span></span>
                </div>
            </button>
            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-dropdown nav-right" data-app-modern-menu="true"><li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#team1-j">Tutorials</a></li>
                    <li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#features11-k">Datasets</a></li>
                    <li class="nav-item"><a class="nav-link link text-black text-primary display-4" href="index.html#features1-o">News</a>
                    </li></ul>
                
                
            </div>
        </div>
    </nav>
</section>

<section class="header3 cid-sA64NaH1Tl" id="header3-1p">

    

    

    <div class="align-center container">
        <div class="row justify-content-end">
            <div class="col-12 col-lg-6">
                <h1 class="mbr-section-title mbr-fonts-style mb-3 display-2"><strong>Facial Expression Recognition</strong></h1>
                
                <p class="mbr-text mbr-fonts-style display-7">Research papers</p>
                
            </div>
        </div>
    </div>
</section>

<section class="content16 cid-sA8ZqFyJVu" id="content16-2v">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-md-10">
                <div class="mbr-section-head align-center mb-4">
                    <h3 class="mbr-section-title mb-0 mbr-fonts-style display-5">
                        <strong>Papers</strong></h3>
                    
                </div>
                <div id="bootstrap-accordion_87" class="panel-group accordionStyles accordion" role="tablist" aria-multiselectable="true">
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse1_87" aria-expanded="false" aria-controls="collapse1">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Caption-Supervised Face Recognition: Training a State-of-the-Art Face Model without Manual Annotation</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse1_87" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_87">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">The advances over the past several years have pushed the performance of face recognition to an amazing level. This great success, to a large extent, is built on top of millions of annotated samples [<a href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123620137.pdf" class="text-primary" target="_blank">Paper</a>}</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse2_87" aria-expanded="false" aria-controls="collapse2">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>A novel non-linear modifier for adaptive illumination normalization for robust face recognition</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse2_87" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_87">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    In this paper, a novel approach is presented for adaptive illumination normalization for face recognition under varying illuminations due to change in angle of light projection. Illumination normalization is performed over some of the low frequency discrete Cosine transform (DCT) coefficients which are computed adaptively based upon the significance of alteration of these coefficients. [<a href="https://www.researchgate.net/publication/338413762_A_novel_non-linear_modifier_for_adaptive_illumination_normalization_for_robust_face_recognition" class="text-primary" target="_blank">Paper</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse3_87" aria-expanded="false" aria-controls="collapse3">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Illumination-robust face recognition based on deep convolutional neural networks architectures</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse3_87" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_87">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    In the last decade, facial recognition techniques are considered the most important fields of research in biometric technology. In this research paper, we present a Face Recognition (FR) system divided into three steps: The Viola-Jones face detection algorithm, facial image enhancement using Modified Contrast Limited Adaptive Histogram Equalization algorithm (M-CLAHE), and feature learning for classification. For learning the features followed by classification we used VGG16, ResNet50 and Inception-v3 Convolutional Neural Networks (CNN) architectures for the proposed system. [<a href="https://www.researchgate.net/publication/338253578_Illumination-robust_face_recognition_based_on_deep_convolutional_neural_networks_architectures" class="text-primary" target="_blank">Paper</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse4_87" aria-expanded="false" aria-controls="collapse4">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>A Novel Approach of Face Recognition Using Optimized Adaptive Illumination Normalization and KELM</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse4_87" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_87">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    Light variations from different directions on the face images cause severe performance degradation in face recognition system. These variations should be nullified or suppressed so that the recognition performance can be improved. Here, the objective is to develop a Face recognition (FR) based on image set is an important topic in computer vision. There are numerous approaches that apply pose estimation method for single image face recognition but few embed pose estimation method into image set-based face recognition. [<a href="https://www.researchgate.net/publication/341339340_A_Novel_Approach_of_Face_Recognition_Using_Optimized_Adaptive_Illumination-Normalization_and_KELM" class="text-primary" target="_blank">Paper</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse5_87" aria-expanded="false" aria-controls="collapse5">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><br><div><strong>Low Resolution Face Recognition Using Generative Adversarial Network&nbsp;</strong></div></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse5_87" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_87">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    Face recognition has a lot of use on smartphone authentication, finding people, etc. Nowadays, face recognition with a constrained environment has achieved very good performance on accuracy. However, the accuracy of existing face recognition methods will gradually decrease when using a dataset with an unconstrained environment. [<a href="https://assets.researchsquare.com/files/rs-36971/v2_stamped.pdf" class="text-primary" target="_blank">Paper</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse6_87" aria-expanded="false" aria-controls="collapse6">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Illumination Compensation of Facial Image Using Combination Algorithm for Face Recognition</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse6_87" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_87">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    So far, biometric identification in general and facial recognition in particular are still being researched and developed for applying in several areas such as security, etc. In this paper, the authors study on some facial image recognition methods that have been researched and published in the world. [<a href="https://media.congnghiepcongnghecao.com.vn/Images/Upload/User/giangnguyen/2020/8/006_19-080.pdf" class="text-primary" target="_blank">Paper</a>]</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content11 cid-sA8Zrs4dFi" id="content11-2w">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
                <div class="mbr-section-btn align-center"><a class="btn btn-black display-4" href="">More Papers</a> 
                    <a class="btn btn-primary-outline display-4" href=""></a></div>
            </div>
        </div>
    </div>
</section>

<section class="content16 cid-sA8ZsgDZU2" id="content16-2x">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-md-10">
                <div class="mbr-section-head align-center mb-4">
                    <h3 class="mbr-section-title mb-0 mbr-fonts-style display-5">
                        <strong>Papers with code</strong></h3>
                    
                </div>
                <div id="bootstrap-accordion_89" class="panel-group accordionStyles accordion" role="tablist" aria-multiselectable="true">
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse1_89" aria-expanded="false" aria-controls="collapse1">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>OpenFace: A general-purpose face recognition library with mobile applications</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse1_89" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_89">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">Cameras are becoming ubiquitous in the Internet of Things (IoT) and can use face recognition technology to improve context. There is a large accuracy gap between today’s publicly available face recognition systems and the state-of-the-art private face recognition systems. This paper presents our OpenFace face recognition library that bridges this accuracy gap. We show that OpenFace provides near-human accuracy on the LFW benchmark and present a new classification benchmark for mobile scenarios. This paper is intended for non-experts interested in using OpenFace and provides a light introduction to the deep neural network techniques we use [<a href="http://reports-archive.adm.cs.cmu.edu/anon/anon/2016/CMU-CS-16-118.pdf" class="text-primary" target="_blank">Paper</a>} [<a href="https://github.com/cmusatyalab/openface" class="text-primary" target="_blank">Code</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse2_89" aria-expanded="false" aria-controls="collapse2">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Consistent Instance False Positive Improves Fairness in Face Recognition</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse2_89" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_89">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    Demographic bias is a significant challenge in practical face recognition systems. Existing methods heavily rely on accurate demographic annotations. However, such annotations are usually unavailable in real scenarios. Moreover, these methods are typically designed for a specific demographic group and are not general enough. In this paper, we propose a false positive rate penalty loss, which mitigates face recognition bias by increasing the consistency of instance False Positive Rate (FPR). Specifically, we first define the instance FPR as the ratio between the number of the non-target similarities above a unified threshold and the total number of the non-target similarities.  [<a href="https://arxiv.org/pdf/2106.05519v1.pdf" class="text-primary" target="_blank">Paper</a>]&nbsp;[<a href="https://github.com/Tencent/TFace" class="text-primary" target="_blank">Code</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse3_89" aria-expanded="false" aria-controls="collapse3">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Multi-Dataset Benchmarks for Masked Identification using Contrastive Representation Learning</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse3_89" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_89">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    The COVID-19 pandemic has drastically changed accepted norms globally. Within the past year, masks have been used as a public health response to limit the spread of the virus.. [<a href="https://arxiv.org/pdf/2106.05596v1.pdf" class="text-primary" target="_blank">Paper</a>]&nbsp;[<a href="https://github.com/sachith500/ContrastiveFaceRepresentation" class="text-primary" target="_blank">Code</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse4_89" aria-expanded="false" aria-controls="collapse4">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>An Efficient Training Approach for Very Large Scale Face Recognition</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse4_89" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_89">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">Face recognition has achieved significant progress in deep-learning era due to the ultra-large-scale and well-labeled datasets. However, training on ultra-large-scale datasets is time-consuming and takes up a lot of hardware resource. Therefore, designing an efficient training approach is crucial and indispensable. The heavy computational and memory costs mainly result from the high dimensionality of the Fully-Connected (FC) layer [<a href="https://arxiv.org/pdf/2105.10375v4.pdf" class="text-primary" target="_blank">Paper</a>]&nbsp;[<a href="https://github.com/tiandunx/FFC" class="text-primary" target="_blank">Code</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse5_89" aria-expanded="false" aria-controls="collapse5">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><div><strong>RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for Image Recognition</strong></div></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse5_89" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_89">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    We propose RepMLP, a multi-layer-perceptron-style neural network building block for image recognition, which is composed of a series of fully-connected (FC) layers. Compared to convolutional layers, FC layers are more efficient, better at modeling the long-range dependencies and positional patterns, but worse at capturing the local structures, hence usually less favored for image recognition... [<a href="https://arxiv.org/pdf/2105.01883v1.pdf" class="text-primary" target="_blank">Paper</a>]&nbsp;[<a href="https://github.com/DingXiaoH/RepMLP" class="text-primary" target="_blank">Code</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse6_89" aria-expanded="false" aria-controls="collapse6">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Face Transformer for Recognition</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse6_89" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_89">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    Recently there has been a growing interest in Transformer not only in NLP but also in computer vision. We wonder if transformer can be used in face recognition and whether it is better than CNNs. Therefore, we investigate the performance of Transformer models in face recognition. Considering the original Transformer may neglect the inter-patch information, we modify the patch generation process and make the tokens with sliding patches which overlaps with each others. The models are trained on CASIA-WebFace and MS-Celeb-1M databases, and evaluated on several mainstream benchmarks, including LFW, SLLFW, CALFW, CPLFW, TALFW, CFP-FP, AGEDB and IJB-C databases. We demonstrate that Face Transformer models trained on a large-scale database, MS-Celeb-1M, achieve comparable performance as CNN with similar number of parameters and MACs. To facilitate further researches, Face Transformer models and codes are available at https://github.com/zhongyy/Face-Transformer. [<a href="https://arxiv.org/pdf/2103.14803v2.pdf" class="text-primary" target="_blank">Paper</a>]&nbsp;[<a href="https://github.com/zhongyy/Face-Transformer" class="text-primary" target="_blank">Code</a>]</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content11 cid-sA8ZtiDCJK" id="content11-2y">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
                <div class="mbr-section-btn align-center"><a class="btn btn-black display-4" href="">More Papers</a> 
                    <a class="btn btn-primary-outline display-4" href=""></a></div>
            </div>
        </div>
    </div>
</section>

<section class="content16 cid-sA8ZubDvSl" id="content16-2z">

    

    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-12 col-md-10">
                <div class="mbr-section-head align-center mb-4">
                    <h3 class="mbr-section-title mb-0 mbr-fonts-style display-5">
                        <strong>Papers with video</strong></h3>
                    
                </div>
                <div id="bootstrap-accordion_91" class="panel-group accordionStyles accordion" role="tablist" aria-multiselectable="true">
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse1_91" aria-expanded="false" aria-controls="collapse1">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Multi-Modal Face Anti-Spoofing Based on Central Difference Networks</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse1_91" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_91">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">Face anti-spoofing (FAS) plays a vital role in securing face recognition systems from presentation attacks. Ex- isting multi-modal FAS methods rely on stacked vanilla convolutions, which is weak in describing detailed intrin- sic information from modalities and easily being ineffec- tive when the domain shifts (e.g., cross attack and cross ethnicity). In this paper, we extend the central difference convolutional networks (CDCN) to a multi-modal ver- sion, intending to capture intrinsic spoofing patterns among three modalities (RGB, depth and infrared).  [<a href="https://arxiv.org/pdf/2004.08388.pdf" class="text-primary" target="_blank">Paper</a>} [<a href="https://www.youtube.com/watch?v=rYLJqx0MXbw" class="text-primary" target="_blank">Video</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse2_91" aria-expanded="false" aria-controls="collapse2">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>How Unique Is a Face: An Investigative Study</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse2_91" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_91">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    Face recognition has been widely accepted as a means of identification in applications ranging from border control to security in the banking sector. Surprisingly, while widely accepted, we still lack the understanding of uniqueness or distinctiveness of faces as biometric modality. In this work, we study the impact of factors such as image resolution, feature representation, database size, age and gender on uniqueness denoted by the Kullback-Leibler divergence between genuine and impostor distributions. [<a href="https://arxiv.org/abs/2102.04965" class="text-primary" target="_blank">Paper</a>] [<a href="https://stream.crossminds.ai/6043175e07e1c35bcb93124a-1615009647313/hls-6043175e07e1c35bcb93124a.m3u8" class="text-primary" target="_blank">Video</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse3_91" aria-expanded="false" aria-controls="collapse3">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Intelligent Frame Selection as a Privacy-Friendlier Alternative to Face Recognition</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse3_91" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_91">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    In the last decade, facial recognition techniques are considered the most important fields of research in biometric technology. In this research paper, we present a Face Recognition (FR) system divided into three steps: The Viola-Jones face detection algorithm, facial image enhancement using Modified Contrast Limited Adaptive Histogram Equalization algorithm (M-CLAHE), and feature learning for classification. For learning the features followed by classification we used VGG16, ResNet50 and Inception-v3 Convolutional Neural Networks (CNN) architectures for the proposed system. [<a href="https://arxiv.org/pdf/2101.07529.pdf" class="text-primary" target="_blank">Paper</a>] [<a href="https://www.youtube.com/watch?v=r36FGPhK3Uo&feature=emb_logo" class="text-primary" target="_blank">Video</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse4_91" aria-expanded="false" aria-controls="collapse4">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Exploring Racial Bias Within Face Recognition via Per-Subject Adversarially-Enabled Data Augmenta...</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse4_91" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_91">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    Whilst face recognition applications are becoming increasingly prevalent within our daily lives, leading approaches in the field still suffer from performance bias to the detriment of some racial profiles within society. In this study, we propose a novel adversarial derived data augmentation methodology that aims to enable dataset balance at a per-subject level via the use of image-to-image transformation for the transfer of sensitive racial characteristic facial features. Our aim is to automatically construct a synthesised dataset by transforming facial images across varying racial domains, while still preserving identity-related features, such that racially dependant features subsequently become irrelevant within the determination of subject identity. [<a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w1/Yucer_Exploring_Racial_Bias_Within_Face_Recognition_via_Per-Subject_Adversarially-Enabled_Data_CVPRW_2020_paper.pdf" class="text-primary" target="_blank">Paper</a>] [<a href="https://www.youtube.com/watch?time_continue=10&v=RM-OI_51a0c&feature=emb_logo" class="text-primary" target="_blank">Video</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse5_91" aria-expanded="false" aria-controls="collapse5">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><div><strong>Low Resolution Face Recognition Using Generative Adversarial Network&nbsp;</strong></div></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse5_91" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_91">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                    Recognizing wild faces is extremely hard as they appear with all kinds of variations. Traditional methods either train with specifically annotated variation data from target domains, or by introducing unlabeled target variation data to adapt from the training data. Instead, we propose a universal representation learning framework that can deal with larger variation unseen in the given training data without leveraging target domain knowledge.  [<a href="https://arxiv.org/pdf/2002.11841.pdf" class="text-primary" target="_blank">Paper</a>] [<a href="https://www.youtube.com/watch?v=fHQfS4F_0Uo" class="text-primary" target="_blank">Video</a>]</p>
                            </div>
                        </div>
                    </div>
                    <div class="card mb-3">
                        <div class="card-header" role="tab" id="headingOne">
                            <a role="button" class="panel-title collapsed" data-toggle="collapse" data-core="" href="#collapse6_91" aria-expanded="false" aria-controls="collapse6">
                                <h6 class="panel-title-edit mbr-fonts-style mb-0 display-4"><strong>Rotation Consistent Margin Loss for Efficient Low-Bit Face Recognition</strong></h6>
                                <span class="sign mbr-iconfont mbri-arrow-down"></span>
                            </a>
                        </div>
                        <div id="collapse6_91" class="panel-collapse noScroll collapse" role="tabpanel" aria-labelledby="headingOne" data-parent="#bootstrap-accordion_91">
                            <div class="panel-body">
                                <p class="mbr-fonts-style panel-text display-4">
                                     In this paper, we consider the low-bit quantization problem of face recognition (FR) under the open-set protocol. Different from well explored low-bit quantization on closed-set image classification task, the open-set task is more sensitive to quantization errors (QEs). [<a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Wu_Rotation_Consistent_Margin_Loss_for_Efficient_Low-Bit_Face_Recognition_CVPR_2020_paper.pdf" class="text-primary" target="_blank">Paper</a>] [<a href="https://www.youtube.com/watch?v=10VZJKRNlrU" class="text-primary" target="_blank">Video</a>]</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="content11 cid-sA8ZuT9Uip" id="content11-30">
    
    <div class="container">
        <div class="row justify-content-center">
            <div class="col-md-12 col-lg-10">
                <div class="mbr-section-btn align-center"><a class="btn btn-black display-4" href="">More Papers</a> 
                    <a class="btn btn-primary-outline display-4" href=""></a></div>
            </div>
        </div>
    </div>
</section>

<section class="footer7 cid-sA64NcEs6w" once="footers" id="footer7-1u">

    

    

    <div class="container">
        <div class="media-container-row align-center mbr-white">
            <div class="col-12">
                <p class="mbr-text mb-0 mbr-fonts-style display-7">
                    © Copyright 2025 AllAboutFace - All Rights Reserved
                </p>
            </div>
        </div>
    </div>
</section><section style="background-color: #fff; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Helvetica Neue', Arial, sans-serif; color:#aaa; font-size:12px; padding: 0; align-items: center; display: flex;"><a href="https://mobirise.site/w" style="flex: 1 1; height: 3rem; padding-left: 1rem;"></a><p style="flex: 0 0 auto; margin:0; padding-right:1rem;">Made with Mobirise - <a href="https://mobirise.site/k" style="color:#aaa;">More info</a></p></section><script src="assets/web/assets/jquery/jquery.min.js"></script>  <script src="assets/popper/popper.min.js"></script>  <script src="assets/tether/tether.min.js"></script>  <script src="assets/bootstrap/js/bootstrap.min.js"></script>  <script src="assets/smoothscroll/smooth-scroll.js"></script>  <script src="assets/dropdown/js/nav-dropdown.js"></script>  <script src="assets/dropdown/js/navbar-dropdown.js"></script>  <script src="assets/touchswipe/jquery.touch-swipe.min.js"></script>  <script src="assets/mbr-switch-arrow/mbr-switch-arrow.js"></script>  <script src="assets/theme/js/script.js"></script>  
  
  
</body>
</html>